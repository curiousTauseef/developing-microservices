
ports for socket.io ???
may need to specify this
use container linking to hook services together
  edits /etc/hosts
  so thats fine...


Need slides for each step and presenter notes


NOTE - moving to the latest version of docker for mac - which is machine and compose
- WILL DO the nscale demo on AWS with overlay network

OUR DEMO SYSTEM MUST HAVE A REAL DEVICE - lightsensitive ??


mac
export DOCKER_IP=$(boot2docker ip)
linux
export DOCKER_IP=localhost


frontend and services etc all need to be git sub modules / repos
- create these at the end from the end state for an nscale topology and demonstration

NSCALE DEMO AT THE END - deploy the whole lot from separate repos show the config and proxy and overlay network
also scale out the services

- Remove node_modules and bower components from step0
- include a git ignore in all to ignore stuff

- optimize the docker build ?
- must have a cached docker registry available - instruct Darrage tomorrow

all done with docker compose but with nscale env vars - the scripts will set these on run etc 
docke compose vars


Step 0 build a docker container: done
===============================
- clone the step 0 repo 
- notes: need to npm install and bower install
- execute index.sh and ensure chart is visible
- create a dockerfile for step0
- build the container
- docker build -t step0 .
- execute the container
- docker run -p 3000:3000 -t -i step1
- solution is in Step1

Step1 add web sockets support:
=============================
- starting point is solution to step0
- move the random code generation to the back end
- rebuild the container 
- execute the container and ensure it works

NEED TO ADD THE SHELL SERVICE INTO step2 - step3 is the end state
add in run.sh etc for development

Step2 add a data writer service and influx container:
====================================================
- starting point is solution to step 1 + a writer service skeleton
- do a docker pull to fectch the influx container
  docker pull 
- run the container
  docker run -d -p 8083:8083 -p 8086:8086 --expose 8090 --expose 8099 tutum/influxdb
- connect to influx
  docker exec -ti fee /opt/influxdb/influx
- create a database
  create database temperature;
- there is a test case use mocha to make this work
- once its working build the container using the docker file
- run the container (boot 2 docker is)
  docker run -p 3001:3001 -e SERVICE_HOST=0.0.0.0 -e SERVICE_PORT=3001 -e INFLUX_HOST=$DOCKER_IP serializer
- curl to test it
  curl -X POST -d "{\"role\": \"serialize\", \"cmd\": \"write\", \"sensorId\": \"1\", \"temperature\": 32}" http://$DOCKER_IP:3001/act  --header "Content-Type:application/json"

Step3 docker compose
====================
- starting point is solution to step 2 + a compose.yml skeleton
use container linking feature - adds hostnames into /etc/hosts
- install docker compose
- kill all running containers
  docker kill $(docker ps -a -q)
- write the compose.yml file
- bring the application up
- check the front end 
- check that you can connect to influx
- check that the curl writes data
- bring the application down again


Step4 add the broker
====================
- starting point is solution to step3 + a broker service
- dockerize the broker
- dockerize the sensor
- add it to the compose.yml (with appropriate env vars
- tear the system up
- use the provided test script to send temperature messages through the broker to the serializer
  and check that they arrive in influx


Step5 add a read function to the serializer (should this be another microservice ?)
===========================================
- starting point is solution to step4 + comments in the code
- add in the read functionality
- restart the system 
- use a curl command to read data from the serializer

link the front end congainer in compose
then run docker exec, install curl and test the call 


apt-get update
apt-get install curl
curl 

curl -X POST -d "{\"role\": \"serialize\", \"cmd\": \"read\", \"sensorId\": \"1\", \"start\": 1441400000000, \"end\": 1441497000671}" http://serializer:3001/act  --header "Content-Type:application/json"


Step6 Hook the front end in
===========================
- starting point is solution to step5 + some comments in the code
- replace the random data functionaity with a seneca call to the reader service
- the read data should be emitted over a web socket
- the solution should send each data point only once
- rebuild containers
- restart the system 
- as you use the test script to push data into influx the front end chrt should update

--------------------> next steps require Matteo and actuator

Step7
add in the actuator - test with curl

Step 8 
hook the actuator into the front end throught the api

Step 9
full end to end working system

Step 10 
nscale demo of system topology using proxy ovelay on aws

Done!!!!


Step2 add the MQTT broker and influx containers: NEED TO DISCUSS WITH MATTEO - THIS INCLUDES THE DEVICE SIMULATOR ALSO ??
CAN THIS BE DELIVERD IN A PREBUILT CONTIAINER IN OUR LOCAL REGISTRY ?
=========================
- starting point is the solution to step1
- add an influx db container
- docker pull influxdb
- start the 


Step3 add a data writer service and hook up to the broker
=========================================================

Step4 connect to influx and view the data

Step6 introduce docker compose
 - pull the system down 
 - pull the entire system back up

Step5 add a data reader service 
 - will break out the reader from the writer - 2 separate services

Step7
 - hook the data reader into the front end
 - tear the system up and view data from the device end to end

Step 8
 - create the actuator service
 - connect it to the front end (add a button and an input field)

 deploy all locally

Step 9 
 - discussion on issues etc
 - nscale config for the system 
 - deploy using nscale show overlay network idea Job done!








